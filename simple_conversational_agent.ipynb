{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wYwnWhlGDu"
      },
      "source": [
        "# Simple Conversational Agent\n",
        "\n",
        "Simple Conversational Agent is an AI-powered chatbot built with LangChain and an LLM (Large Language Model). Designed for seamless, context-aware conversations, it leverages LangChainâ€™s framework to enhance dialogue with memory and tool integration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0rq3m__kNx6"
      },
      "source": [
        "**Download necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2WG6sgOvLmrg"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install langchain_groq\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQVCfGlPjsIL"
      },
      "source": [
        "**Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM2Vk5wfL4aU"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NpjBljXEMVi4"
      },
      "outputs": [],
      "source": [
        "#Create a simple in-memory store for chat histories\n",
        "store = {}\n",
        "\n",
        "def get_chat_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V8i6bAUe-YOU"
      },
      "outputs": [],
      "source": [
        "# Load variables from .env file\n",
        "load_dotenv()\n",
        "# Load the API key from the .env file\n",
        "api_key = os.getenv(\"API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M3haLAcDM0bO"
      },
      "outputs": [],
      "source": [
        "# Initialize the Groq model with LangChain\n",
        "llm = ChatGroq(\n",
        "    model_name=\"llama3-70b-8192\",\n",
        "    api_key= api_key\n",
        ")\n",
        "\n",
        "# Define the prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create the LLMChain\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zchJIM44NXGx"
      },
      "outputs": [],
      "source": [
        "# Chain with message history\n",
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N53a3JdFNmZl",
        "outputId": "79a62686-e3b6-48d5-9afa-910f31caada3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your question: Hello! How are you?\n",
            "Question: Hello! How are you?\n",
            "Response: content=\"Hello! I'm doing great, thanks for asking! I'm a large language model, so I don't have feelings like humans do, but I'm always happy to chat with you and assist with any questions or tasks you may have. How about you? How's your day going so far?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 28, 'total_tokens': 89, 'completion_time': 0.174285714, 'prompt_time': 0.000109749, 'queue_time': 0.24018883200000002, 'total_time': 0.174395463}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None} id='run-2588aff7-f2ea-4a88-9826-9bd6b2bc3ff6-0' usage_metadata={'input_tokens': 28, 'output_tokens': 61, 'total_tokens': 89}\n",
            "\n",
            "Please enter your question: what is capital of india?\n",
            "Question: what is capital of india?\n",
            "Response: content='The capital of India is New Delhi!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 104, 'total_tokens': 113, 'completion_time': 0.026668076, 'prompt_time': 0.001036198, 'queue_time': 0.23948865000000003, 'total_time': 0.027704274}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None} id='run-120c1b70-5208-4642-a13f-7b68762cbb1b-0' usage_metadata={'input_tokens': 104, 'output_tokens': 9, 'total_tokens': 113}\n",
            "\n",
            "Please enter your question: What was my previous message?\n",
            "Question: What was my previous message?\n",
            "Response: content='Your previous message was \"what is capital of india?\"' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 128, 'total_tokens': 140, 'completion_time': 0.034285714, 'prompt_time': 0.001165187, 'queue_time': 0.240097501, 'total_time': 0.035450901}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None} id='run-f6c5b99c-e21f-4ef2-a6a5-fdbf4244cd7f-0' usage_metadata={'input_tokens': 128, 'output_tokens': 12, 'total_tokens': 140}\n",
            "\n",
            "Please enter your question: exit\n",
            "Goodbye! I have a great day!\n"
          ]
        }
      ],
      "source": [
        "session_id = \"1\"\n",
        "\n",
        "while True:\n",
        "    question = input(\"Please enter your question: \")\n",
        "\n",
        "    if question == \"exit\":\n",
        "        print(\"Goodbye! I have a great day!\")\n",
        "        break\n",
        "\n",
        "    else :\n",
        "        response = chain_with_history.invoke(\n",
        "        {\"input\": question},\n",
        "        config={\"configurable\": {\"session_id\": session_id}})\n",
        "\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Response: {response}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHkefM_kOs_h"
      },
      "source": [
        "**Print the conversation history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP3gzbboOn8K",
        "outputId": "931bb618-53a0-402a-ef0d-c190a4206078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Conversation History:\n",
            "human : Hello! How are you?\n",
            "\n",
            "ai : Hello! I'm doing great, thanks for asking! I'm a large language model, so I don't have feelings like humans do, but I'm always happy to chat with you and assist with any questions or tasks you may have. How about you? How's your day going so far?\n",
            "\n",
            "human : what is capital of india?\n",
            "\n",
            "ai : The capital of India is New Delhi!\n",
            "\n",
            "human : What was my previous message?\n",
            "\n",
            "ai : Your previous message was \"what is capital of india?\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nConversation History:\")\n",
        "\n",
        "for message in store[session_id].messages:\n",
        "    print(f\"{message.type} : {message.content}\\n\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
