{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wYwnWhlGDu"
      },
      "source": [
        "# Simple Question-Answering Agent\n",
        "\n",
        "The Simple Question-Answer Agent, built with LangChain and the Ollama LLM model, is designed to comprehend user queries and deliver clear, concise, and relevant responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0rq3m__kNx6"
      },
      "source": [
        "**Download necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xZDzdpYYVdiB"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_groq\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQVCfGlPjsIL"
      },
      "source": [
        "**Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJVTjAVfV4X1"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M_K5esFr7JtT"
      },
      "outputs": [],
      "source": [
        "# Load variables from .env file\n",
        "load_dotenv()\n",
        "# Load the API key from the .env file\n",
        "api_key = os.getenv(\"API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qld55l9bV9du"
      },
      "outputs": [],
      "source": [
        "# Initialize the Groq model with LangChain\n",
        "llm = ChatGroq(\n",
        "    model_name=\"llama3-70b-8192\",\n",
        "    api_key= api_key\n",
        ")\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"\"\"\n",
        "You are a helpful AI assistant. Your task is to answer the user's question to the best of your ability.\n",
        "\n",
        "User's question: {question}\n",
        "\n",
        "Please provide a clear and concise answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template= template, input_variables=[\"question\"])\n",
        "\n",
        "# Create the LLMChain\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7gDdEPvyfSm9"
      },
      "outputs": [],
      "source": [
        "# Define the get_answer function\n",
        "def get_answer(question):\n",
        "    \"\"\"\n",
        "    Get an answer to the given question using the QA chain.\n",
        "    \"\"\"\n",
        "\n",
        "    input_variables = {\"question\": question}\n",
        "    response = chain.invoke(input_variables)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_LNQ5jWq-6",
        "outputId": "5778b4f0-d6f8-4757-89f5-a8d34bac831d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your question: what is capital of India?\n",
            "Question: what is capital of India?\n",
            "Answer: The capital of India is New Delhi.\n",
            "\n",
            "Please enter your question: what is machine learning?\n",
            "Question: what is machine learning?\n",
            "Answer: Machine learning is a subfield of artificial intelligence (AI) that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. In other words, machine learning enables computers to automatically improve their performance on a task by learning from experience and adapting to new data.\n",
            "\n",
            "Machine learning algorithms are designed to analyze and learn patterns in data, and then use that knowledge to make predictions, classify objects, or make decisions. This is achieved through a process of trial and error, where the algorithm adjusts its parameters to minimize errors and maximize accuracy.\n",
            "\n",
            "There are three main types of machine learning:\n",
            "\n",
            "1. **Supervised learning**: The algorithm is trained on labeled data, where the correct output is already known. The goal is to learn a mapping between input data and the corresponding output labels.\n",
            "2. **Unsupervised learning**: The algorithm is trained on unlabeled data, and it must find patterns or structures in the data on its own.\n",
            "3. **Reinforcement learning**: The algorithm learns by interacting with an environment and receiving feedback in the form of rewards or penalties.\n",
            "\n",
            "Machine learning has numerous applications in areas such as image and speech recognition, natural language processing, recommender systems, autonomous vehicles, and more.\n",
            "\n",
            "I hope that helps! Do you have any follow-up questions?\n",
            "\n",
            "Please enter your question: exit\n",
            "Goodbye! I have a great day!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    question = input(\"Please enter your question: \")\n",
        "\n",
        "    if question == \"exit\":\n",
        "        print(\"Goodbye! I have a great day!\")\n",
        "        break\n",
        "\n",
        "    else :\n",
        "        answer = get_answer(question)\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
